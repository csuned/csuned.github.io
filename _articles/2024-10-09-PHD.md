---
title: "PH-Dropout: Practical Epistemic Uncertainty Quantification for View Synthesis"
category: Research Paper
permalink: /articles/2024-10-09-PHD
excerpt: "A very efficient way to get the Epistemic Uncertainty Quantification of both NeRF and Gaussian splats. (Open source project with Paper under review)"
venue: "Arxiv Preprint"
date: 2024-10-09
---

This is paper is under review. It is open sourece.

[Access to Code](https://github.com/thanostriantafyllou3/ph-dropout)

Abstract: View synthesis using Neural Radiance Fields (NeRF) and Gaussian Splatting (GS) has demonstrated impressive fidelity in rendering real-world scenarios. However, practical methods for accurate and efficient epistemic Uncertainty Quantification (UQ) in view synthesis are lacking. Existing approaches for NeRF either introduce significant computational overhead (e.g., “10x increase in training time” or “10x repeated training”) or are limited to specific uncertainty conditions or models. Notably, GS models lack any systematic approach for comprehensive epistemic UQ. This capability is crucial for improving the robustness and scalability of neu- ral view synthesis, enabling active model updates, error estimation, and scalable ensemble modeling based on uncertainty. In this paper, we revisit NeRF and GS- based methods from a function approximation perspective, identifying key differences and connections in 3D representation learning. Building on these insights, we introduce PH-DROPOUT (Post hoc Dropout), the first real-time and accurate method for epistemic uncertainty estimation that operates directly on pre-trained NeRF and GS models. Extensive evaluations validate our theoretical findings and demonstrate the effectiveness of PH-DROPOUT.
